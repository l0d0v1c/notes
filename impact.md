# Impact

![banner](medias/computerg.jpg)

 Cette note reprend des réflexions sur l'impact des LLM sur des aspects plus philosophiques ou ethnologiques.

# L'universalité du langage
Les LLMs sont entrainés sur des grands corpus de données sans se préoccuper des langues. Le réseau de neurones apprend donc indifféremment du français, de l'anglais, du grec, mais aussi du python, du C, du javascript. Il ept également apprendre des séquences génétiques (suites de A,T,G,C) ou bien des séquences d'acides aminés (constituant des protéines) ou bien des graphes moléculaires comme les SMILES.

Cela place le langage comme un universel de la représentation du savoir. Cela concerne les images aussi, et l'art ou la musique, langage codé par des partitions. Cela signifie probablement qu'il faut relire Witgnenstein et Shanon.

Finalement seules les odeurs échappent encore au langage et donc aux IA.
Cette universalité du langage pose plusieurs questions:
- Les IA sont entrainées sur la représentation linguistique que les humains se font du monde. Une suite de A,T,G,C fait un génome, mais ce n'est pas la réalité physique de l'ADN et encore moins de la vie. L'IA produit donc une carte qui n'est toujours pas le territoire. Mais c'est une meilleure carte que la nôtre, plus générale.
- Si un seul réseau de neurones comme LLaMA qui pour sa version 13B ne fait que 8Go compressés en 4 bits contient une trentaine de langages humains et artificiels, y a-t-il un langage fondamental qui sous-tendrait toutes les représentations, un sanskrit caché?
- Le langage est le moteur de l'incompréhension par ses ambiguïtés et ses interprétations. Peut-on générer une langue qui ne produirait aucune de ces ambiguïtés, quels que soient l'émetteur et le récepteur. C'est finalement le cas des langues à règles comme les langages informatiques. Or, même dans ce cas, le comportement des gros logiciels, dont les failles de sécurité font parfois un peu peur, est bien moins prévisible qu'attendu.


[Retour au sommaire](?p=index)

