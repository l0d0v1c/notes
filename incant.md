# Programmation incantatoire

![banner](medias/shaman.jpg)

 Quand j'ai commencé à jouer avec les intelligences artificielles génératives, en 2015, c'était pour créer de nouvelles molécules. À l'époque, on pointait dans un espace latent LSTM et une nouvelle molécule, valide, apparaissait. Pas de l'alchimie, mais de l'alt-chimie. On était pas mal excité.

  C'est ainsi que 8 ans plus tard, tout le monde a découvert les LLM dans l'espoir déraisonnable et dans la peur irraisonnée. Cela mérite une réflexion.

 L'expérience, quand on met le nez dans le moteur, est plus troublante que ce qu'on en dit. Les IA génératives LLM de type LLaMA sont des animaux bien intéressants à observer et qui interrogent sur le fonctionnement de notre propre cerveau.

 Imaginons que vous rencontriez un avocat dans un bar et que vous lui demandiez si vous avez de droit de monter un business dans lequel vous donneriez des conseils médicaux. Il vous dirait spontanément que c'est de l'exercice illégal de la médecine. Pour avoir une bonne réponse, il faudrait que vous donniez des éléments de contexte. "Je suis médecin, mais j'ai un diplôme de médecine chilien." Et là vous pouvez obtenir une réponse en reposant la question.

 Pour obtenir une meilleure réponse, il faut savoir poser de meilleures questions et cela se fait en décrivant de manière efficace un contexte. 
La fenêtre de contexte des IA génératives est petite (2048 token pour LLaMA ce qui vaut les 2/3 en mots, mais MPT_7B, qui vient de sortir, propose déjà 65k). Mais même lorsqu'on interroge un humain, un contexte trop long n'est pas une bonne idée. Il faut être synthétique, ne pas être ambigu.
 Il a été observé que 5 exemples donnés à un modèle de 7 milliards de paramètres le faisaient dépasser en performance un modèle à 13 milliards qui n'aurait pas ces exemples.
 C'est également vrai pour les humains. Je peux vous dire que je croule sous les questions hors contexte. "Tu penses quoi de?" "Tu dirais quoi pour?" Les gens sont surpris de mon manque d'avis si aucun contexte n'est donné. "Est-ce que tu penses que ce serait mieux si j'entrainais mes modèles avec des données des forums d'adolescents?" Ben si tu veux discuter de la relation complexe entre la personnalité de Shiva et celle de Dionysos...non. Si tu veux parler comédons, oui. Une question sans contexte ne vaut rien et la réponse encore moins.

 Ce que les LLM nous obligent aussi à considérer c'est la bien faible utilité des règles. On nous a élevé dans l'idée cartésienne que tout était règles à apprendre, grammaire, mathématiques... Mais les LLM ne se programment pas avec des règles, mais avec des contextes, c'est-à-dire des histoires, des descriptions de personnalités, des impressions à donner, des manières et des valeurs.
 Un prompt de LLM raconte une histoire et le résultat sera bon ou mauvais selon que l'histoire sera bien ou mal faite.
 Cette histoire comporte également des expériences. On dira qu'autrefois un homme a posé une question dans un certain contexte et que la bonne réponse fût celle-là ou bien celle-ci, en n’omettant pas qu'elle puisse être un je-ne-sais-pas.
 L'éducation d'un enfant, par les parents ou par l'école, c'est un long préprompt qui fait la différence entre un adulte qui pense et un adulte qui rumine.

 Les LLM introduisent une nouvelle façon de programmer, sans lignes de code, sans règles. Il s'agit de raconter des histoires et des expériences. Une très grande révolution, un passage de la mécanique à l'organique, du compliqué au complexe, de la causalité à l'interaction. 
Ce n'est pas juste une nouvelle technologie. C'est une révélation sur le fonctionnement de la cognition. La programmation par incantation ou invocation. Un darshan.


Donc avec les IA comme avec moi:

- Donnez votre contexte
- Avec franchise et sans dissimulation ni interprétation possible sur vos intentions
- Acceptez une réponse insatisfaisante
- Améliorez votre contexte pour poser la question suivante


[Retour au sommaire](?p=index)

